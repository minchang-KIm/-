{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e93997",
   "metadata": {
    "papermill": {
     "duration": 0.007969,
     "end_time": "2024-10-15T20:44:50.714846",
     "exception": false,
     "start_time": "2024-10-15T20:44:50.706877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1: 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85977b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:44:50.729570Z",
     "iopub.status.busy": "2024-10-15T20:44:50.729270Z",
     "iopub.status.idle": "2024-10-15T20:45:09.987298Z",
     "shell.execute_reply": "2024-10-15T20:45:09.986159Z"
    },
    "papermill": {
     "duration": 19.268386,
     "end_time": "2024-10-15T20:45:09.990057",
     "exception": false,
     "start_time": "2024-10-15T20:44:50.721671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\r\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662f209",
   "metadata": {
    "papermill": {
     "duration": 0.007278,
     "end_time": "2024-10-15T20:45:10.005309",
     "exception": false,
     "start_time": "2024-10-15T20:45:09.998031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2: 커스텀 Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f77ed1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:10.022836Z",
     "iopub.status.busy": "2024-10-15T20:45:10.021859Z",
     "iopub.status.idle": "2024-10-15T20:45:10.029228Z",
     "shell.execute_reply": "2024-10-15T20:45:10.028401Z"
    },
    "papermill": {
     "duration": 0.017516,
     "end_time": "2024-10-15T20:45:10.031095",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.013579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# - 이미지와 레이블을 전달받아 학습 및 검증을 위한 데이터를 제공\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f0484",
   "metadata": {
    "papermill": {
     "duration": 0.006748,
     "end_time": "2024-10-15T20:45:10.044756",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.038008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3: Squeeze-and-Excitation 모듈 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b80fdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:10.059394Z",
     "iopub.status.busy": "2024-10-15T20:45:10.059090Z",
     "iopub.status.idle": "2024-10-15T20:45:10.065652Z",
     "shell.execute_reply": "2024-10-15T20:45:10.064837Z"
    },
    "papermill": {
     "duration": 0.016177,
     "end_time": "2024-10-15T20:45:10.067504",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.051327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SE Block 정의\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=4):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.adaptive_avg_pool2d(x, 1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = torch.sigmoid(self.fc2(out))\n",
    "        return x * out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c5c33",
   "metadata": {
    "papermill": {
     "duration": 0.006449,
     "end_time": "2024-10-15T20:45:10.081003",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.074554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4: Conv-BN-ReLU 모듈 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6639c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:10.096091Z",
     "iopub.status.busy": "2024-10-15T20:45:10.095805Z",
     "iopub.status.idle": "2024-10-15T20:45:10.101565Z",
     "shell.execute_reply": "2024-10-15T20:45:10.100766Z"
    },
    "papermill": {
     "duration": 0.015709,
     "end_time": "2024-10-15T20:45:10.103584",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.087875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# - 일반적인 Convolution-BatchNorm-활성화 함수 블록\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(ConvBNReLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9cb13",
   "metadata": {
    "papermill": {
     "duration": 0.006942,
     "end_time": "2024-10-15T20:45:10.117198",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.110256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5: Inverted Residual Block 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af554597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:10.132564Z",
     "iopub.status.busy": "2024-10-15T20:45:10.132246Z",
     "iopub.status.idle": "2024-10-15T20:45:10.142548Z",
     "shell.execute_reply": "2024-10-15T20:45:10.141523Z"
    },
    "papermill": {
     "duration": 0.020126,
     "end_time": "2024-10-15T20:45:10.144623",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.124497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inverted Residual Block 정의\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio=4):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        \n",
    "        # stride가 1이고 in_channels와 out_channels가 같으면 skip connection을 사용\n",
    "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
    "\n",
    "        # 1x1 Conv -> Expansion\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_dim)\n",
    "\n",
    "        # Depthwise 3x3 Conv\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
    "\n",
    "        # SE Block 적용\n",
    "        self.se = SqueezeExcitation(hidden_dim)\n",
    "\n",
    "        # 1x1 Conv -> Projection\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 확장 단계\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "\n",
    "        # Depthwise Conv + SE Block\n",
    "        out = F.relu(self.bn2(self.conv2(out)), inplace=True)\n",
    "        out = self.se(out)  # Squeeze-and-Excitation 적용\n",
    "\n",
    "        # 축소 단계\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        # Skip connection 적용\n",
    "        if self.use_res_connect:\n",
    "            return x + out  # 입력과 출력을 더함 (Residual 연결)\n",
    "        else:\n",
    "            return out  # skip connection이 없는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d2458",
   "metadata": {
    "papermill": {
     "duration": 0.006764,
     "end_time": "2024-10-15T20:45:10.158198",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.151434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Squeeze-and-Excitation block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376ca058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:10.174290Z",
     "iopub.status.busy": "2024-10-15T20:45:10.173965Z",
     "iopub.status.idle": "2024-10-15T20:45:10.180998Z",
     "shell.execute_reply": "2024-10-15T20:45:10.180168Z"
    },
    "papermill": {
     "duration": 0.017611,
     "end_time": "2024-10-15T20:45:10.183032",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.165421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        # 최소 크기 보장\n",
    "        reduced_channels = max(1, in_channels // reduction_ratio)\n",
    "        self.fc1 = nn.Linear(in_channels, reduced_channels)\n",
    "        self.fc2 = nn.Linear(reduced_channels, in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, _, _ = x.size()\n",
    "        y = F.adaptive_avg_pool2d(x, 1).view(batch, channels)\n",
    "        \n",
    "        # Swish 사용: x * sigmoid(x)\n",
    "        y = torch.sigmoid(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y)).view(batch, channels, 1, 1)\n",
    "        return x * y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af30650",
   "metadata": {
    "papermill": {
     "duration": 0.007224,
     "end_time": "2024-10-15T20:45:10.197379",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.190155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6: NOLA 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc695f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:10.213623Z",
     "iopub.status.busy": "2024-10-15T20:45:10.213270Z",
     "iopub.status.idle": "2024-10-15T20:45:11.255262Z",
     "shell.execute_reply": "2024-10-15T20:45:11.254319Z"
    },
    "papermill": {
     "duration": 1.053128,
     "end_time": "2024-10-15T20:45:11.258049",
     "exception": false,
     "start_time": "2024-10-15T20:45:10.204921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 112, 112]             432\n",
      "       BatchNorm2d-2         [-1, 16, 112, 112]              32\n",
      "            Conv2d-3         [-1, 48, 112, 112]             768\n",
      "       BatchNorm2d-4         [-1, 48, 112, 112]              96\n",
      "            Conv2d-5           [-1, 48, 56, 56]             432\n",
      "       BatchNorm2d-6           [-1, 48, 56, 56]              96\n",
      "            Linear-7                    [-1, 3]             147\n",
      "            Linear-8                   [-1, 48]             192\n",
      " SqueezeExcitation-9           [-1, 48, 56, 56]               0\n",
      "           Conv2d-10           [-1, 24, 56, 56]           1,152\n",
      "      BatchNorm2d-11           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-12           [-1, 24, 56, 56]               0\n",
      "           Conv2d-13           [-1, 72, 56, 56]           1,728\n",
      "      BatchNorm2d-14           [-1, 72, 56, 56]             144\n",
      "           Conv2d-15           [-1, 72, 28, 28]             648\n",
      "      BatchNorm2d-16           [-1, 72, 28, 28]             144\n",
      "           Linear-17                    [-1, 4]             292\n",
      "           Linear-18                   [-1, 72]             360\n",
      "SqueezeExcitation-19           [-1, 72, 28, 28]               0\n",
      "           Conv2d-20           [-1, 32, 28, 28]           2,304\n",
      "      BatchNorm2d-21           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-22           [-1, 32, 28, 28]               0\n",
      "           Conv2d-23          [-1, 128, 28, 28]           4,096\n",
      "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
      "           Conv2d-25          [-1, 128, 14, 14]           1,152\n",
      "      BatchNorm2d-26          [-1, 128, 14, 14]             256\n",
      "           Linear-27                    [-1, 8]           1,032\n",
      "           Linear-28                  [-1, 128]           1,152\n",
      "SqueezeExcitation-29          [-1, 128, 14, 14]               0\n",
      "           Conv2d-30           [-1, 64, 14, 14]           8,192\n",
      "      BatchNorm2d-31           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-32           [-1, 64, 14, 14]               0\n",
      "           Conv2d-33          [-1, 256, 14, 14]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 14, 14]             512\n",
      "           Conv2d-35            [-1, 256, 7, 7]           2,304\n",
      "      BatchNorm2d-36            [-1, 256, 7, 7]             512\n",
      "           Linear-37                   [-1, 16]           4,112\n",
      "           Linear-38                  [-1, 256]           4,352\n",
      "SqueezeExcitation-39            [-1, 256, 7, 7]               0\n",
      "           Conv2d-40            [-1, 128, 7, 7]          32,768\n",
      "      BatchNorm2d-41            [-1, 128, 7, 7]             256\n",
      " InvertedResidual-42            [-1, 128, 7, 7]               0\n",
      "AdaptiveAvgPool2d-43            [-1, 128, 1, 1]               0\n",
      "           Linear-44                  [-1, 100]          12,900\n",
      "================================================================\n",
      "Total params: 99,443\n",
      "Trainable params: 99,443\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 26.32\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 27.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# NOLA_MobileNetV3 모델 정의\n",
    "class NOLA_MobileNetV3(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(NOLA_MobileNetV3, self).__init__()\n",
    "\n",
    "        # 기본 Conv 레이어\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Inverted Residual Blocks와 SE Block 사용\n",
    "        self.block1 = InvertedResidual(16, 24, stride=2, expand_ratio=3)\n",
    "        self.block2 = InvertedResidual(24, 32, stride=2, expand_ratio=3)\n",
    "        self.block3 = InvertedResidual(32, 64, stride=2, expand_ratio=4)\n",
    "        self.block4 = InvertedResidual(64, 128, stride=2, expand_ratio=4)\n",
    "\n",
    "        # GAP 적용\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = NOLA_MobileNetV3().cuda()\n",
    "summary(model, (3, 224, 224))  # 모델 구조 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f2f58",
   "metadata": {
    "papermill": {
     "duration": 0.006885,
     "end_time": "2024-10-15T20:45:11.272308",
     "exception": false,
     "start_time": "2024-10-15T20:45:11.265423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NOLA LinearLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543b2cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:11.288171Z",
     "iopub.status.busy": "2024-10-15T20:45:11.287854Z",
     "iopub.status.idle": "2024-10-15T20:45:11.302867Z",
     "shell.execute_reply": "2024-10-15T20:45:11.301967Z"
    },
    "papermill": {
     "duration": 0.025408,
     "end_time": "2024-10-15T20:45:11.304856",
     "exception": false,
     "start_time": "2024-10-15T20:45:11.279448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerateParams(torch.autograd.Function):\n",
    "    # Generate parameters on the fly with random basis\n",
    "    \n",
    "    @staticmethod    \n",
    "    def forward(ctx, coefficients, out_dim, in_dim, seed): \n",
    "        num_basis = coefficients.shape[0]\n",
    "        Out = torch.zeros(out_dim, in_dim).to(coefficients.device)\n",
    "        rand_seed = torch.randint(int(1e10), (1,))\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        W = torch.zeros(num_basis, out_dim, in_dim, \n",
    "                        device=coefficients.device, dtype=coefficients.dtype)\n",
    "        nn.init.uniform_(W, a=-1.0, b=1.0)\n",
    "        Out = torch.einsum('b,boi->oi', coefficients, W)\n",
    "        \n",
    "        params = torch.autograd.Variable(torch.tensor([out_dim, in_dim, seed]))\n",
    "        ctx.save_for_backward(coefficients, params)\n",
    "        torch.manual_seed(rand_seed)\n",
    "        return Out \n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        coefficients, params = ctx.saved_tensors\n",
    "        num_basis = coefficients.shape[0]\n",
    "\n",
    "        out_dim, in_dim, seed = params\n",
    "        rand_seed = torch.randint(int(1e10), (1,))\n",
    "        torch.manual_seed(seed)\n",
    "        grad_coefficients = torch.empty(0).to(grad_output.device)\n",
    "\n",
    "        W = torch.zeros(num_basis, out_dim, in_dim, \n",
    "                        device=coefficients.device, dtype=coefficients.dtype)\n",
    "        nn.init.uniform_(W, a=-1.0, b=1.0) \n",
    "        W = W.permute(1, 2, 0).reshape(-1, num_basis)\n",
    "        grad_coefficients = torch.einsum('d,dl->l', grad_output.flatten(), W)\n",
    "\n",
    "        torch.manual_seed(rand_seed)    \n",
    "        return grad_coefficients, None, None, None\n",
    "\n",
    "\n",
    "# NOLA Linear Layer 정의 수정\n",
    "class NOLALinear(nn.Linear): \n",
    "    def __init__(self, in_features: int, out_features: int, coefficients: torch.Tensor, seed: int, num_basis=128, **kwargs):\n",
    "        super(NOLALinear, self).__init__(in_features, out_features, **kwargs)\n",
    "        self.num_basis = num_basis \n",
    "        self.generate_params = GenerateParams.apply\n",
    "        self.coefficients = nn.Parameter(coefficients, requires_grad=True)\n",
    "        self.seed = nn.Parameter(torch.tensor(seed), requires_grad=False)\n",
    "        self.weight.requires_grad = False\n",
    "        \n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, num_basis={}'.format(\n",
    "            self.in_features, self.out_features, self.num_basis)  \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        W = self.generate_params(self.coefficients,\n",
    "                          self.out_features,\n",
    "                          self.in_features,\n",
    "                          self.seed) + self.weight\n",
    "        return x @ W.t()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2a43e",
   "metadata": {
    "papermill": {
     "duration": 0.006894,
     "end_time": "2024-10-15T20:45:11.318663",
     "exception": false,
     "start_time": "2024-10-15T20:45:11.311769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7: 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d02750d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:11.334183Z",
     "iopub.status.busy": "2024-10-15T20:45:11.333557Z",
     "iopub.status.idle": "2024-10-15T20:45:11.340002Z",
     "shell.execute_reply": "2024-10-15T20:45:11.339159Z"
    },
    "papermill": {
     "duration": 0.016249,
     "end_time": "2024-10-15T20:45:11.341983",
     "exception": false,
     "start_time": "2024-10-15T20:45:11.325734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 여러 Augmentation 기법 적용 (좌우반전, 회전, 크기 조절 등)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 이 부분을 가장 마지막에 두어야 합니다.\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 이미지 정규화\n",
    "    transforms.RandomErasing()  # RandomErasing 추가\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79756a0",
   "metadata": {
    "papermill": {
     "duration": 0.007049,
     "end_time": "2024-10-15T20:45:11.356190",
     "exception": false,
     "start_time": "2024-10-15T20:45:11.349141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8: 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7842f3b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:11.371826Z",
     "iopub.status.busy": "2024-10-15T20:45:11.371107Z",
     "iopub.status.idle": "2024-10-15T20:45:13.710773Z",
     "shell.execute_reply": "2024-10-15T20:45:13.709734Z"
    },
    "papermill": {
     "duration": 2.350306,
     "end_time": "2024-10-15T20:45:13.713352",
     "exception": false,
     "start_time": "2024-10-15T20:45:11.363046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# - 학습 및 검증 데이터 로드 (Kaggle에서 데이터 불러오기)\n",
    "train = np.load('/kaggle/input/2024-ai-challenge/trainset.npy')\n",
    "label = np.load('/kaggle/input/2024-ai-challenge/trainlabel.npy')\n",
    "\n",
    "# 학습 및 검증 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size=0.2, random_state=42)\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = CustomDataset(X_val, y_val, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "#배치사이즈 튜닝해보기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0773fe",
   "metadata": {
    "papermill": {
     "duration": 0.007319,
     "end_time": "2024-10-15T20:45:13.728086",
     "exception": false,
     "start_time": "2024-10-15T20:45:13.720767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 10: 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ff5b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:13.744130Z",
     "iopub.status.busy": "2024-10-15T20:45:13.743742Z",
     "iopub.status.idle": "2024-10-15T20:45:13.750648Z",
     "shell.execute_reply": "2024-10-15T20:45:13.749751Z"
    },
    "papermill": {
     "duration": 0.017367,
     "end_time": "2024-10-15T20:45:13.752980",
     "exception": false,
     "start_time": "2024-10-15T20:45:13.735613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 500  # 최대 Epoch 수 (200으로 설정, 조기 종료가 있으면 더 적을 수 있음)\n",
    "learning_rate = 0.01  # 초기 학습률 (0.01로 조정)\n",
    "weight_decay = 1e-4  # weight decay (L2 정규화)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n",
    "\n",
    "# Early Stopping 기준\n",
    "early_stopping_patience = 20\n",
    "best_val_accuracy = 0\n",
    "early_stopping_counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b2106",
   "metadata": {
    "papermill": {
     "duration": 0.006815,
     "end_time": "2024-10-15T20:45:13.769572",
     "exception": false,
     "start_time": "2024-10-15T20:45:13.762757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 11: 학습 및 검증 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828f1c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:45:13.785707Z",
     "iopub.status.busy": "2024-10-15T20:45:13.785323Z",
     "iopub.status.idle": "2024-10-16T01:03:54.394413Z",
     "shell.execute_reply": "2024-10-16T01:03:54.393022Z"
    },
    "papermill": {
     "duration": 15520.642308,
     "end_time": "2024-10-16T01:03:54.419082",
     "exception": false,
     "start_time": "2024-10-15T20:45:13.776774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 3.8474, Train Accuracy: 0.1022\n",
      "Validation Accuracy: 0.1419\n",
      "Current learning rate: [0.009999998012695082]\n",
      "New best model saved at epoch 1 with val accuracy: 0.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/500], Loss: 3.3597, Train Accuracy: 0.1813\n",
      "Validation Accuracy: 0.1305\n",
      "Current learning rate: [0.009999998319181792]\n",
      "Epoch [3/500], Loss: 3.1319, Train Accuracy: 0.2241\n",
      "Validation Accuracy: 0.1898\n",
      "Current learning rate: [0.009999996444570183]\n",
      "New best model saved at epoch 3 with val accuracy: 0.1898\n",
      "Epoch [4/500], Loss: 2.9950, Train Accuracy: 0.2515\n",
      "Validation Accuracy: 0.2178\n",
      "Current learning rate: [0.009999995318172283]\n",
      "New best model saved at epoch 4 with val accuracy: 0.2178\n",
      "Epoch [5/500], Loss: 2.8941, Train Accuracy: 0.2707\n",
      "Validation Accuracy: 0.2448\n",
      "Current learning rate: [0.009999994085439388]\n",
      "New best model saved at epoch 5 with val accuracy: 0.2448\n",
      "Epoch [6/500], Loss: 2.8244, Train Accuracy: 0.2864\n",
      "Validation Accuracy: 0.2167\n",
      "Current learning rate: [0.009999995365344043]\n",
      "Epoch [7/500], Loss: 2.7659, Train Accuracy: 0.2963\n",
      "Validation Accuracy: 0.2140\n",
      "Current learning rate: [0.00999999548011665]\n",
      "Epoch [8/500], Loss: 2.7325, Train Accuracy: 0.3054\n",
      "Validation Accuracy: 0.2431\n",
      "Current learning rate: [0.009999994167300817]\n",
      "Epoch [9/500], Loss: 2.6835, Train Accuracy: 0.3157\n",
      "Validation Accuracy: 0.2498\n",
      "Current learning rate: [0.00999999384136417]\n",
      "New best model saved at epoch 9 with val accuracy: 0.2498\n",
      "Epoch [10/500], Loss: 2.6399, Train Accuracy: 0.3226\n",
      "Validation Accuracy: 0.2625\n",
      "Current learning rate: [0.00999999319922726]\n",
      "New best model saved at epoch 10 with val accuracy: 0.2625\n",
      "Epoch [11/500], Loss: 2.6134, Train Accuracy: 0.3295\n",
      "Validation Accuracy: 0.2630\n",
      "Current learning rate: [0.009999993173294886]\n",
      "New best model saved at epoch 11 with val accuracy: 0.2630\n",
      "Epoch [12/500], Loss: 2.5725, Train Accuracy: 0.3364\n",
      "Validation Accuracy: 0.2730\n",
      "Current learning rate: [0.009999992644284339]\n",
      "New best model saved at epoch 12 with val accuracy: 0.2730\n",
      "Epoch [13/500], Loss: 2.5348, Train Accuracy: 0.3454\n",
      "Validation Accuracy: 0.2818\n",
      "Current learning rate: [0.009999992162426809]\n",
      "New best model saved at epoch 13 with val accuracy: 0.2818\n",
      "Epoch [14/500], Loss: 2.5156, Train Accuracy: 0.3510\n",
      "Validation Accuracy: 0.2959\n",
      "Current learning rate: [0.009999991358491715]\n",
      "New best model saved at epoch 14 with val accuracy: 0.2959\n",
      "Epoch [15/500], Loss: 2.4859, Train Accuracy: 0.3548\n",
      "Validation Accuracy: 0.2557\n",
      "Current learning rate: [0.009999993547008278]\n",
      "Epoch [16/500], Loss: 2.4743, Train Accuracy: 0.3574\n",
      "Validation Accuracy: 0.3094\n",
      "Current learning rate: [0.009999990551992544]\n",
      "New best model saved at epoch 16 with val accuracy: 0.3094\n",
      "Epoch [17/500], Loss: 2.4621, Train Accuracy: 0.3598\n",
      "Validation Accuracy: 0.2998\n",
      "Current learning rate: [0.00999999112919824]\n",
      "Epoch [18/500], Loss: 2.4425, Train Accuracy: 0.3646\n",
      "Validation Accuracy: 0.3066\n",
      "Current learning rate: [0.009999990722223375]\n",
      "Epoch [19/500], Loss: 2.4267, Train Accuracy: 0.3661\n",
      "Validation Accuracy: 0.2682\n",
      "Current learning rate: [0.009999992900672851]\n",
      "Epoch [20/500], Loss: 2.4086, Train Accuracy: 0.3739\n",
      "Validation Accuracy: 0.2816\n",
      "Current learning rate: [0.009999992173547873]\n",
      "Epoch [21/500], Loss: 2.4015, Train Accuracy: 0.3748\n",
      "Validation Accuracy: 0.3371\n",
      "Current learning rate: [0.009999988784540071]\n",
      "New best model saved at epoch 21 with val accuracy: 0.3371\n",
      "Epoch [22/500], Loss: 2.3766, Train Accuracy: 0.3805\n",
      "Validation Accuracy: 0.2689\n",
      "Current learning rate: [0.009999992863566117]\n",
      "Epoch [23/500], Loss: 2.3661, Train Accuracy: 0.3795\n",
      "Validation Accuracy: 0.2600\n",
      "Current learning rate: [0.009999993328148908]\n",
      "Epoch [24/500], Loss: 2.3621, Train Accuracy: 0.3815\n",
      "Validation Accuracy: 0.2600\n",
      "Current learning rate: [0.009999993328148908]\n",
      "Epoch [25/500], Loss: 2.3493, Train Accuracy: 0.3872\n",
      "Validation Accuracy: 0.3124\n",
      "Current learning rate: [0.009999990367885061]\n",
      "Epoch [26/500], Loss: 2.3374, Train Accuracy: 0.3885\n",
      "Validation Accuracy: 0.3322\n",
      "Current learning rate: [0.009999989108220418]\n",
      "Epoch [27/500], Loss: 2.3439, Train Accuracy: 0.3857\n",
      "Validation Accuracy: 0.3310\n",
      "Current learning rate: [0.00999998918676662]\n",
      "Epoch [28/500], Loss: 2.3285, Train Accuracy: 0.3913\n",
      "Validation Accuracy: 0.2789\n",
      "Current learning rate: [0.009999992322909455]\n",
      "Epoch [29/500], Loss: 2.3313, Train Accuracy: 0.3883\n",
      "Validation Accuracy: 0.3087\n",
      "Current learning rate: [0.009999990594695333]\n",
      "Epoch [30/500], Loss: 2.3148, Train Accuracy: 0.3936\n",
      "Validation Accuracy: 0.2736\n",
      "Current learning rate: [0.009999992611916001]\n",
      "Epoch [31/500], Loss: 2.3042, Train Accuracy: 0.3951\n",
      "Validation Accuracy: 0.3081\n",
      "Current learning rate: [0.009999990631220743]\n",
      "Epoch [32/500], Loss: 2.3002, Train Accuracy: 0.3982\n",
      "Validation Accuracy: 0.3354\n",
      "Current learning rate: [0.009999988897374239]\n",
      "Epoch [33/500], Loss: 2.2932, Train Accuracy: 0.3993\n",
      "Validation Accuracy: 0.3216\n",
      "Current learning rate: [0.009999989792211157]\n",
      "Epoch [34/500], Loss: 2.2961, Train Accuracy: 0.3984\n",
      "Validation Accuracy: 0.3354\n",
      "Current learning rate: [0.009999988897374239]\n",
      "Epoch [35/500], Loss: 2.2872, Train Accuracy: 0.3990\n",
      "Validation Accuracy: 0.3303\n",
      "Current learning rate: [0.009999989232453972]\n",
      "Epoch [36/500], Loss: 2.2822, Train Accuracy: 0.4011\n",
      "Validation Accuracy: 0.3180\n",
      "Current learning rate: [0.009999990019464567]\n",
      "Epoch [37/500], Loss: 2.2687, Train Accuracy: 0.4007\n",
      "Validation Accuracy: 0.3147\n",
      "Current learning rate: [0.009999990225532888]\n",
      "Epoch [38/500], Loss: 2.2747, Train Accuracy: 0.4030\n",
      "Validation Accuracy: 0.3250\n",
      "Current learning rate: [0.009999989575233974]\n",
      "Epoch [39/500], Loss: 2.2789, Train Accuracy: 0.4031\n",
      "Validation Accuracy: 0.3377\n",
      "Current learning rate: [0.009999988744580047]\n",
      "New best model saved at epoch 39 with val accuracy: 0.3377\n",
      "Epoch [40/500], Loss: 2.2704, Train Accuracy: 0.4034\n",
      "Validation Accuracy: 0.3371\n",
      "Current learning rate: [0.009999988784540071]\n",
      "Epoch [41/500], Loss: 2.2540, Train Accuracy: 0.4032\n",
      "Validation Accuracy: 0.3339\n",
      "Current learning rate: [0.009999988996460058]\n",
      "Epoch [42/500], Loss: 2.2637, Train Accuracy: 0.4058\n",
      "Validation Accuracy: 0.3523\n",
      "Current learning rate: [0.009999987750316878]\n",
      "New best model saved at epoch 42 with val accuracy: 0.3523\n",
      "Epoch [43/500], Loss: 2.2480, Train Accuracy: 0.4083\n",
      "Validation Accuracy: 0.3315\n",
      "Current learning rate: [0.00999998915407358]\n",
      "Epoch [44/500], Loss: 2.2549, Train Accuracy: 0.4047\n",
      "Validation Accuracy: 0.3525\n",
      "Current learning rate: [0.009999987736404694]\n",
      "New best model saved at epoch 44 with val accuracy: 0.3525\n",
      "Epoch [45/500], Loss: 2.2454, Train Accuracy: 0.4087\n",
      "Validation Accuracy: 0.3376\n",
      "Current learning rate: [0.009999988751244984]\n",
      "Epoch [46/500], Loss: 2.2357, Train Accuracy: 0.4114\n",
      "Validation Accuracy: 0.3208\n",
      "Current learning rate: [0.009999989842932993]\n",
      "Epoch [47/500], Loss: 2.2363, Train Accuracy: 0.4103\n",
      "Validation Accuracy: 0.3174\n",
      "Current learning rate: [0.009999990057091422]\n",
      "Epoch [48/500], Loss: 2.2306, Train Accuracy: 0.4130\n",
      "Validation Accuracy: 0.3347\n",
      "Current learning rate: [0.009999988943669559]\n",
      "Epoch [49/500], Loss: 2.2427, Train Accuracy: 0.4112\n",
      "Validation Accuracy: 0.3426\n",
      "Current learning rate: [0.009999988415579995]\n",
      "Epoch [50/500], Loss: 2.2348, Train Accuracy: 0.4128\n",
      "Validation Accuracy: 0.3279\n",
      "Current learning rate: [0.009999989388362029]\n",
      "Epoch [51/500], Loss: 2.2283, Train Accuracy: 0.4129\n",
      "Validation Accuracy: 0.3518\n",
      "Current learning rate: [0.009999987785062793]\n",
      "Epoch [52/500], Loss: 2.2232, Train Accuracy: 0.4112\n",
      "Validation Accuracy: 0.3241\n",
      "Current learning rate: [0.009999989632891176]\n",
      "Epoch [53/500], Loss: 2.2203, Train Accuracy: 0.4133\n",
      "Validation Accuracy: 0.3434\n",
      "Current learning rate: [0.009999988361415649]\n",
      "Epoch [54/500], Loss: 2.2208, Train Accuracy: 0.4129\n",
      "Validation Accuracy: 0.3428\n",
      "Current learning rate: [0.009999988402050752]\n",
      "Epoch [55/500], Loss: 2.2249, Train Accuracy: 0.4117\n",
      "Validation Accuracy: 0.3275\n",
      "Current learning rate: [0.009999989414236165]\n",
      "Epoch [56/500], Loss: 2.2213, Train Accuracy: 0.4140\n",
      "Validation Accuracy: 0.3412\n",
      "Current learning rate: [0.00999998851006362]\n",
      "Epoch [57/500], Loss: 2.2220, Train Accuracy: 0.4152\n",
      "Validation Accuracy: 0.3598\n",
      "Current learning rate: [0.00999998722320642]\n",
      "New best model saved at epoch 57 with val accuracy: 0.3598\n",
      "Epoch [58/500], Loss: 2.2087, Train Accuracy: 0.4171\n",
      "Validation Accuracy: 0.3190\n",
      "Current learning rate: [0.009999989956595227]\n",
      "Epoch [59/500], Loss: 2.2047, Train Accuracy: 0.4164\n",
      "Validation Accuracy: 0.3423\n",
      "Current learning rate: [0.009999988435859055]\n",
      "Epoch [60/500], Loss: 2.1974, Train Accuracy: 0.4156\n",
      "Validation Accuracy: 0.3416\n",
      "Current learning rate: [0.009999988483107776]\n",
      "Epoch [61/500], Loss: 2.2064, Train Accuracy: 0.4164\n",
      "Validation Accuracy: 0.2975\n",
      "Current learning rate: [0.009999991264785799]\n",
      "Epoch [62/500], Loss: 2.2026, Train Accuracy: 0.4169\n",
      "Validation Accuracy: 0.3474\n",
      "Current learning rate: [0.009999988088698952]\n",
      "Epoch [63/500], Loss: 2.2062, Train Accuracy: 0.4152\n",
      "Validation Accuracy: 0.3242\n",
      "Current learning rate: [0.009999989626492716]\n",
      "Epoch [64/500], Loss: 2.2003, Train Accuracy: 0.4191\n",
      "Validation Accuracy: 0.3492\n",
      "Current learning rate: [0.009999987964946055]\n",
      "Epoch [65/500], Loss: 2.1898, Train Accuracy: 0.4205\n",
      "Validation Accuracy: 0.3351\n",
      "Current learning rate: [0.009999988917226935]\n",
      "Epoch [66/500], Loss: 2.1918, Train Accuracy: 0.4185\n",
      "Validation Accuracy: 0.3483\n",
      "Current learning rate: [0.009999988026902449]\n",
      "Epoch [67/500], Loss: 2.2109, Train Accuracy: 0.4172\n",
      "Validation Accuracy: 0.2781\n",
      "Current learning rate: [0.00999999236688839]\n",
      "Epoch [68/500], Loss: 2.2397, Train Accuracy: 0.4107\n",
      "Validation Accuracy: 0.3297\n",
      "Current learning rate: [0.009999989271537578]\n",
      "Epoch [69/500], Loss: 2.2222, Train Accuracy: 0.4144\n",
      "Validation Accuracy: 0.3499\n",
      "Current learning rate: [0.009999987916647211]\n",
      "Epoch [70/500], Loss: 2.2157, Train Accuracy: 0.4115\n",
      "Validation Accuracy: 0.3650\n",
      "Current learning rate: [0.0099999868512253]\n",
      "New best model saved at epoch 70 with val accuracy: 0.3650\n",
      "Epoch [71/500], Loss: 2.2233, Train Accuracy: 0.4115\n",
      "Validation Accuracy: 0.3420\n",
      "Current learning rate: [0.00999998845612035]\n",
      "Epoch [72/500], Loss: 2.2087, Train Accuracy: 0.4146\n",
      "Validation Accuracy: 0.2668\n",
      "Current learning rate: [0.009999992974596153]\n",
      "Epoch [73/500], Loss: 2.2126, Train Accuracy: 0.4173\n",
      "Validation Accuracy: 0.3516\n",
      "Current learning rate: [0.009999987798947339]\n",
      "Epoch [74/500], Loss: 2.2117, Train Accuracy: 0.4162\n",
      "Validation Accuracy: 0.3664\n",
      "Current learning rate: [0.009999986750164587]\n",
      "New best model saved at epoch 74 with val accuracy: 0.3664\n",
      "Epoch [75/500], Loss: 2.2096, Train Accuracy: 0.4178\n",
      "Validation Accuracy: 0.3059\n",
      "Current learning rate: [0.009999990764539278]\n",
      "Epoch [76/500], Loss: 2.2008, Train Accuracy: 0.4177\n",
      "Validation Accuracy: 0.2762\n",
      "Current learning rate: [0.00999999247083205]\n",
      "Epoch [77/500], Loss: 2.2085, Train Accuracy: 0.4169\n",
      "Validation Accuracy: 0.3286\n",
      "Current learning rate: [0.009999989343006294]\n",
      "Epoch [78/500], Loss: 2.2036, Train Accuracy: 0.4187\n",
      "Validation Accuracy: 0.2875\n",
      "Current learning rate: [0.009999991842157331]\n",
      "Epoch [79/500], Loss: 2.1956, Train Accuracy: 0.4193\n",
      "Validation Accuracy: 0.3432\n",
      "Current learning rate: [0.009999988374968578]\n",
      "Epoch [80/500], Loss: 2.2025, Train Accuracy: 0.4178\n",
      "Validation Accuracy: 0.3178\n",
      "Current learning rate: [0.009999990032014747]\n",
      "Epoch [81/500], Loss: 2.2014, Train Accuracy: 0.4153\n",
      "Validation Accuracy: 0.3340\n",
      "Current learning rate: [0.009999988989868156]\n",
      "Epoch [82/500], Loss: 2.2008, Train Accuracy: 0.4163\n",
      "Validation Accuracy: 0.3294\n",
      "Current learning rate: [0.009999989291052733]\n",
      "Epoch [83/500], Loss: 2.1917, Train Accuracy: 0.4195\n",
      "Validation Accuracy: 0.3262\n",
      "Current learning rate: [0.00999998949810899]\n",
      "Epoch [84/500], Loss: 2.1938, Train Accuracy: 0.4181\n",
      "Validation Accuracy: 0.3006\n",
      "Current learning rate: [0.009999991081792583]\n",
      "Epoch [85/500], Loss: 2.1835, Train Accuracy: 0.4253\n",
      "Validation Accuracy: 0.3157\n",
      "Current learning rate: [0.009999990163314943]\n",
      "Epoch [86/500], Loss: 2.1921, Train Accuracy: 0.4214\n",
      "Validation Accuracy: 0.2689\n",
      "Current learning rate: [0.009999992863566117]\n",
      "Epoch [87/500], Loss: 2.1911, Train Accuracy: 0.4208\n",
      "Validation Accuracy: 0.3556\n",
      "Current learning rate: [0.0099999875197562]\n",
      "Epoch [88/500], Loss: 2.1941, Train Accuracy: 0.4208\n",
      "Validation Accuracy: 0.3230\n",
      "Current learning rate: [0.009999989703143959]\n",
      "Epoch [89/500], Loss: 2.1945, Train Accuracy: 0.4211\n",
      "Validation Accuracy: 0.3128\n",
      "Current learning rate: [0.00999999034320317]\n",
      "Epoch [90/500], Loss: 2.1855, Train Accuracy: 0.4224\n",
      "Validation Accuracy: 0.3075\n",
      "Current learning rate: [0.009999990667675093]\n",
      "Epoch [91/500], Loss: 2.1864, Train Accuracy: 0.4216\n",
      "Validation Accuracy: 0.2074\n",
      "Current learning rate: [0.009999995754613956]\n",
      "Epoch [92/500], Loss: 2.1857, Train Accuracy: 0.4227\n",
      "Validation Accuracy: 0.3280\n",
      "Current learning rate: [0.00999998938188856]\n",
      "Epoch [93/500], Loss: 2.1926, Train Accuracy: 0.4199\n",
      "Validation Accuracy: 0.3302\n",
      "Current learning rate: [0.009999989238972842]\n",
      "Epoch [94/500], Loss: 2.1810, Train Accuracy: 0.4208\n",
      "Validation Accuracy: 0.3371\n",
      "Current learning rate: [0.009999988784540071]\n",
      "Early stopping at epoch 94\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - 모델 학습 및 검증을 수행하는 메인 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # 학습 루프\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features, batch_labels = batch_features.cuda(), batch_labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    # 학습 결과 출력\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct / len(train_dataset)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # 검증 루프\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for val_features, val_labels in val_loader:\n",
    "            val_features, val_labels = val_features.cuda(), val_labels.cuda()\n",
    "            val_outputs = model(val_features)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    # 검증 정확도 출력\n",
    "    val_accuracy = val_correct / len(val_dataset)\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 스케줄러를 통해 학습률 조정\n",
    "    scheduler.step(val_accuracy)\n",
    "    print(\"Current learning rate:\", scheduler.get_last_lr())\n",
    "    \n",
    "    # Early Stopping 체크\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        early_stopping_counter = 0\n",
    "        # 모델 저장\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"New best model saved at epoch {epoch + 1} with val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0169b",
   "metadata": {
    "papermill": {
     "duration": 0.022843,
     "end_time": "2024-10-16T01:03:54.463741",
     "exception": false,
     "start_time": "2024-10-16T01:03:54.440898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 12: 테스트 데이터 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78fcfa33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T01:03:54.509090Z",
     "iopub.status.busy": "2024-10-16T01:03:54.508726Z",
     "iopub.status.idle": "2024-10-16T01:05:08.889774Z",
     "shell.execute_reply": "2024-10-16T01:05:08.888646Z"
    },
    "papermill": {
     "duration": 74.429024,
     "end_time": "2024-10-16T01:05:08.914306",
     "exception": false,
     "start_time": "2024-10-16T01:03:54.485282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/145435278.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))  # 가장 성능이 좋은 모델 로드\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file has been saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - 가장 성능이 좋은 모델을 로드하고 테스트 데이터에 대한 예측을 수행\n",
    "model.load_state_dict(torch.load('best_model.pth'))  # 가장 성능이 좋은 모델 로드\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test = np.load('/kaggle/input/2024-ai-challenge/testset.npy')  # 테스트 데이터 불러오기\n",
    "    test_dataset = CustomDataset(test, np.zeros((test.shape[0], 100)), transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    for test_features, _ in test_loader:\n",
    "        test_features = test_features.cuda()\n",
    "        outputs = model(test_features)\n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "# 예측 결과 합치기\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# 예측된 클래스의 인덱스를 얻음\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "submission_df = pd.DataFrame({\n",
    "    'id_idx': np.arange(len(predicted_classes)),\n",
    "    'label': predicted_classes\n",
    "})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "submission_filename = 'submission.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"Submission file has been saved as '{submission_filename}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9473141,
     "sourceId": 84531,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15623.429498,
   "end_time": "2024-10-16T01:05:11.484356",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-15T20:44:48.054858",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
