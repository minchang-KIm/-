{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6712b44",
   "metadata": {
    "papermill": {
     "duration": 0.006739,
     "end_time": "2024-10-15T02:04:42.344218",
     "exception": false,
     "start_time": "2024-10-15T02:04:42.337479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1: 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db50427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:04:42.357583Z",
     "iopub.status.busy": "2024-10-15T02:04:42.357242Z",
     "iopub.status.idle": "2024-10-15T02:05:01.687368Z",
     "shell.execute_reply": "2024-10-15T02:05:01.686441Z"
    },
    "papermill": {
     "duration": 19.339295,
     "end_time": "2024-10-15T02:05:01.689742",
     "exception": false,
     "start_time": "2024-10-15T02:04:42.350447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\r\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1\r\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39344975",
   "metadata": {
    "papermill": {
     "duration": 0.00621,
     "end_time": "2024-10-15T02:05:01.702737",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.696527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2: 커스텀 Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930d5c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:01.718466Z",
     "iopub.status.busy": "2024-10-15T02:05:01.717740Z",
     "iopub.status.idle": "2024-10-15T02:05:01.724822Z",
     "shell.execute_reply": "2024-10-15T02:05:01.723949Z"
    },
    "papermill": {
     "duration": 0.017742,
     "end_time": "2024-10-15T02:05:01.726803",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.709061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# - 이미지와 레이블을 전달받아 학습 및 검증을 위한 데이터를 제공\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f7104",
   "metadata": {
    "papermill": {
     "duration": 0.006377,
     "end_time": "2024-10-15T02:05:01.739608",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.733231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3: Squeeze-and-Excitation 모듈 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d468ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:01.753496Z",
     "iopub.status.busy": "2024-10-15T02:05:01.753170Z",
     "iopub.status.idle": "2024-10-15T02:05:01.759707Z",
     "shell.execute_reply": "2024-10-15T02:05:01.758829Z"
    },
    "papermill": {
     "duration": 0.015709,
     "end_time": "2024-10-15T02:05:01.761689",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.745980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SE Block 정의\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=4):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.adaptive_avg_pool2d(x, 1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = torch.sigmoid(self.fc2(out))\n",
    "        return x * out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6e16f",
   "metadata": {
    "papermill": {
     "duration": 0.006273,
     "end_time": "2024-10-15T02:05:01.774452",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.768179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4: Conv-BN-ReLU 모듈 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d5c29d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:01.788429Z",
     "iopub.status.busy": "2024-10-15T02:05:01.788124Z",
     "iopub.status.idle": "2024-10-15T02:05:01.793911Z",
     "shell.execute_reply": "2024-10-15T02:05:01.793089Z"
    },
    "papermill": {
     "duration": 0.014996,
     "end_time": "2024-10-15T02:05:01.795819",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.780823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# - 일반적인 Convolution-BatchNorm-활성화 함수 블록\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(ConvBNReLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a884f0c9",
   "metadata": {
    "papermill": {
     "duration": 0.006234,
     "end_time": "2024-10-15T02:05:01.808671",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.802437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5: Inverted Residual Block 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7b3318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:01.822735Z",
     "iopub.status.busy": "2024-10-15T02:05:01.822459Z",
     "iopub.status.idle": "2024-10-15T02:05:01.831226Z",
     "shell.execute_reply": "2024-10-15T02:05:01.830544Z"
    },
    "papermill": {
     "duration": 0.018029,
     "end_time": "2024-10-15T02:05:01.833110",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.815081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio=4):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.se = SqueezeExcitation(hidden_dim)  # SE Block 추가\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = F.relu(self.bn2(self.conv2(out)), inplace=True)\n",
    "        out = self.se(out)  # SE Block 적용\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        if self.use_res_connect:\n",
    "            return x + out\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba5d16e",
   "metadata": {
    "papermill": {
     "duration": 0.006344,
     "end_time": "2024-10-15T02:05:01.845978",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.839634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Squeeze-and-Excitation block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b27bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:01.860265Z",
     "iopub.status.busy": "2024-10-15T02:05:01.859986Z",
     "iopub.status.idle": "2024-10-15T02:05:01.866375Z",
     "shell.execute_reply": "2024-10-15T02:05:01.865594Z"
    },
    "papermill": {
     "duration": 0.015613,
     "end_time": "2024-10-15T02:05:01.868157",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.852544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=32):  # reduction_ratio 증가\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        reduced_channels = in_channels // reduction_ratio\n",
    "        self.fc1 = nn.Linear(in_channels, reduced_channels)\n",
    "        self.fc2 = nn.Linear(reduced_channels, in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, _, _ = x.size()\n",
    "        y = F.adaptive_avg_pool2d(x, 1).view(batch, channels)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y)).view(batch, channels, 1, 1)\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026cfd3",
   "metadata": {
    "papermill": {
     "duration": 0.006314,
     "end_time": "2024-10-15T02:05:01.881006",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.874692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6: NOLA 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2901ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:01.895172Z",
     "iopub.status.busy": "2024-10-15T02:05:01.894919Z",
     "iopub.status.idle": "2024-10-15T02:05:01.903367Z",
     "shell.execute_reply": "2024-10-15T02:05:01.902536Z"
    },
    "papermill": {
     "duration": 0.017834,
     "end_time": "2024-10-15T02:05:01.905346",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.887512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NOLA_MobileNetV3(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(NOLA_MobileNetV3, self).__init__()\n",
    "\n",
    "        # 기본 Conv 레이어\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # Inverted Residual Blocks와 SE Block 사용\n",
    "        self.block1 = InvertedResidual(16, 24, stride=2)\n",
    "        self.block2 = InvertedResidual(24, 32, stride=2)\n",
    "        self.block3 = InvertedResidual(32, 64, stride=2)\n",
    "        self.block4 = InvertedResidual(64, 128, stride=2)\n",
    "\n",
    "        # GAP 적용\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6336ec",
   "metadata": {
    "papermill": {
     "duration": 0.006508,
     "end_time": "2024-10-15T02:05:01.918452",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.911944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NOLA LinearLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21cad398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:01.933097Z",
     "iopub.status.busy": "2024-10-15T02:05:01.932835Z",
     "iopub.status.idle": "2024-10-15T02:05:01.947272Z",
     "shell.execute_reply": "2024-10-15T02:05:01.946629Z"
    },
    "papermill": {
     "duration": 0.024092,
     "end_time": "2024-10-15T02:05:01.949144",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.925052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerateParams(torch.autograd.Function):\n",
    "    # Generate parameters on the fly with random basis\n",
    "    \n",
    "    @staticmethod    \n",
    "    def forward(ctx, coefficients, out_dim, in_dim, seed): \n",
    "        num_basis = coefficients.shape[0]\n",
    "        Out = torch.zeros(out_dim, in_dim).to(coefficients.device)\n",
    "        rand_seed = torch.randint(int(1e10), (1,))\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        W = torch.zeros(num_basis, out_dim, in_dim, \n",
    "                        device=coefficients.device, dtype=coefficients.dtype)\n",
    "        nn.init.uniform_(W, a=-1.0, b=1.0)\n",
    "        Out = torch.einsum('b,boi->oi', coefficients, W)\n",
    "        \n",
    "        params = torch.autograd.Variable(torch.tensor([out_dim, in_dim, seed]))\n",
    "        ctx.save_for_backward(coefficients, params)\n",
    "        torch.manual_seed(rand_seed)\n",
    "        return Out \n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        coefficients, params = ctx.saved_tensors\n",
    "        num_basis = coefficients.shape[0]\n",
    "\n",
    "        out_dim, in_dim, seed = params\n",
    "        rand_seed = torch.randint(int(1e10), (1,))\n",
    "        torch.manual_seed(seed)\n",
    "        grad_coefficients = torch.empty(0).to(grad_output.device)\n",
    "\n",
    "        W = torch.zeros(num_basis, out_dim, in_dim, \n",
    "                        device=coefficients.device, dtype=coefficients.dtype)\n",
    "        nn.init.uniform_(W, a=-1.0, b=1.0) \n",
    "        W = W.permute(1, 2, 0).reshape(-1, num_basis)\n",
    "        grad_coefficients = torch.einsum('d,dl->l', grad_output.flatten(), W)\n",
    "\n",
    "        torch.manual_seed(rand_seed)    \n",
    "        return grad_coefficients, None, None, None\n",
    "\n",
    "\n",
    "# NOLA Linear Layer 정의 수정\n",
    "class NOLALinear(nn.Linear): \n",
    "    def __init__(self, in_features: int, out_features: int, coefficients: torch.Tensor, seed: int, num_basis=128, **kwargs):\n",
    "        super(NOLALinear, self).__init__(in_features, out_features, **kwargs)\n",
    "        self.num_basis = num_basis \n",
    "        self.generate_params = GenerateParams.apply\n",
    "        self.coefficients = nn.Parameter(coefficients, requires_grad=True)\n",
    "        self.seed = nn.Parameter(torch.tensor(seed), requires_grad=False)\n",
    "        self.weight.requires_grad = False\n",
    "        \n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, num_basis={}'.format(\n",
    "            self.in_features, self.out_features, self.num_basis)  \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        W = self.generate_params(self.coefficients,\n",
    "                          self.out_features,\n",
    "                          self.in_features,\n",
    "                          self.seed) + self.weight\n",
    "        return x @ W.t()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5fbc77",
   "metadata": {
    "papermill": {
     "duration": 0.006489,
     "end_time": "2024-10-15T02:05:01.962372",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.955883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7: 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3bc1e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:01.976718Z",
     "iopub.status.busy": "2024-10-15T02:05:01.976450Z",
     "iopub.status.idle": "2024-10-15T02:05:01.983097Z",
     "shell.execute_reply": "2024-10-15T02:05:01.982264Z"
    },
    "papermill": {
     "duration": 0.016092,
     "end_time": "2024-10-15T02:05:01.985042",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.968950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# - 여러 Augmentation 기법 적용 (좌우반전, 회전, 크기 조절 등)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 이미지 정규화\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6aa64",
   "metadata": {
    "papermill": {
     "duration": 0.006466,
     "end_time": "2024-10-15T02:05:01.998201",
     "exception": false,
     "start_time": "2024-10-15T02:05:01.991735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8: 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb78f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:02.012713Z",
     "iopub.status.busy": "2024-10-15T02:05:02.012428Z",
     "iopub.status.idle": "2024-10-15T02:05:04.812565Z",
     "shell.execute_reply": "2024-10-15T02:05:04.811756Z"
    },
    "papermill": {
     "duration": 2.81002,
     "end_time": "2024-10-15T02:05:04.814918",
     "exception": false,
     "start_time": "2024-10-15T02:05:02.004898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# - 학습 및 검증 데이터 로드 (Kaggle에서 데이터 불러오기)\n",
    "train = np.load('/kaggle/input/2024-ai-challenge/trainset.npy')\n",
    "label = np.load('/kaggle/input/2024-ai-challenge/trainlabel.npy')\n",
    "\n",
    "# 학습 및 검증 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, label, test_size=0.2, random_state=42)\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(X_val, y_val, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89966d",
   "metadata": {
    "papermill": {
     "duration": 0.006721,
     "end_time": "2024-10-15T02:05:04.828837",
     "exception": false,
     "start_time": "2024-10-15T02:05:04.822116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9: 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c83776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:04.843848Z",
     "iopub.status.busy": "2024-10-15T02:05:04.843521Z",
     "iopub.status.idle": "2024-10-15T02:05:05.829188Z",
     "shell.execute_reply": "2024-10-15T02:05:05.828329Z"
    },
    "papermill": {
     "duration": 0.996457,
     "end_time": "2024-10-15T02:05:05.832029",
     "exception": false,
     "start_time": "2024-10-15T02:05:04.835572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 112, 112]             432\n",
      "       BatchNorm2d-2         [-1, 16, 112, 112]              32\n",
      "            Conv2d-3         [-1, 64, 112, 112]           1,024\n",
      "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
      "            Conv2d-5           [-1, 64, 56, 56]             576\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "            Linear-7                    [-1, 2]             130\n",
      "            Linear-8                   [-1, 64]             192\n",
      " SqueezeExcitation-9           [-1, 64, 56, 56]               0\n",
      "           Conv2d-10           [-1, 24, 56, 56]           1,536\n",
      "      BatchNorm2d-11           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-12           [-1, 24, 56, 56]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]           2,304\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "           Conv2d-15           [-1, 96, 28, 28]             864\n",
      "      BatchNorm2d-16           [-1, 96, 28, 28]             192\n",
      "           Linear-17                    [-1, 3]             291\n",
      "           Linear-18                   [-1, 96]             384\n",
      "SqueezeExcitation-19           [-1, 96, 28, 28]               0\n",
      "           Conv2d-20           [-1, 32, 28, 28]           3,072\n",
      "      BatchNorm2d-21           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-22           [-1, 32, 28, 28]               0\n",
      "           Conv2d-23          [-1, 128, 28, 28]           4,096\n",
      "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
      "           Conv2d-25          [-1, 128, 14, 14]           1,152\n",
      "      BatchNorm2d-26          [-1, 128, 14, 14]             256\n",
      "           Linear-27                    [-1, 4]             516\n",
      "           Linear-28                  [-1, 128]             640\n",
      "SqueezeExcitation-29          [-1, 128, 14, 14]               0\n",
      "           Conv2d-30           [-1, 64, 14, 14]           8,192\n",
      "      BatchNorm2d-31           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-32           [-1, 64, 14, 14]               0\n",
      "           Conv2d-33          [-1, 256, 14, 14]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 14, 14]             512\n",
      "           Conv2d-35            [-1, 256, 7, 7]           2,304\n",
      "      BatchNorm2d-36            [-1, 256, 7, 7]             512\n",
      "           Linear-37                    [-1, 8]           2,056\n",
      "           Linear-38                  [-1, 256]           2,304\n",
      "SqueezeExcitation-39            [-1, 256, 7, 7]               0\n",
      "           Conv2d-40            [-1, 128, 7, 7]          32,768\n",
      "      BatchNorm2d-41            [-1, 128, 7, 7]             256\n",
      " InvertedResidual-42            [-1, 128, 7, 7]               0\n",
      "AdaptiveAvgPool2d-43            [-1, 128, 1, 1]               0\n",
      "           Linear-44                  [-1, 100]          12,900\n",
      "================================================================\n",
      "Total params: 96,821\n",
      "Trainable params: 96,821\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 32.11\n",
      "Params size (MB): 0.37\n",
      "Estimated Total Size (MB): 33.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - MobileNetV3 모델을 초기화하고 구조를 요약\n",
    "model = NOLA_MobileNetV3(num_classes=100).cuda()  # 클래스 수 설정\n",
    "summary(model, (3, 224, 224))  # 모델 구조 요약\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6616b",
   "metadata": {
    "papermill": {
     "duration": 0.006873,
     "end_time": "2024-10-15T02:05:05.846104",
     "exception": false,
     "start_time": "2024-10-15T02:05:05.839231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 10: 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9ebd0db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:05.861809Z",
     "iopub.status.busy": "2024-10-15T02:05:05.861042Z",
     "iopub.status.idle": "2024-10-15T02:05:05.869699Z",
     "shell.execute_reply": "2024-10-15T02:05:05.868797Z"
    },
    "papermill": {
     "duration": 0.018663,
     "end_time": "2024-10-15T02:05:05.871670",
     "exception": false,
     "start_time": "2024-10-15T02:05:05.853007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - 학습 및 검증을 위한 설정을 준비\n",
    "num_epochs = 1000  # 최대 Epoch 수\n",
    "learning_rate = 0.001  # 초기 학습률\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Early Stopping 기준\n",
    "early_stopping_patience = 10\n",
    "best_val_accuracy = 0\n",
    "early_stopping_counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef414f3",
   "metadata": {
    "papermill": {
     "duration": 0.007006,
     "end_time": "2024-10-15T02:05:05.885777",
     "exception": false,
     "start_time": "2024-10-15T02:05:05.878771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 11: 학습 및 검증 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31b66dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T02:05:05.902079Z",
     "iopub.status.busy": "2024-10-15T02:05:05.901302Z",
     "iopub.status.idle": "2024-10-15T12:36:27.024874Z",
     "shell.execute_reply": "2024-10-15T12:36:27.023777Z"
    },
    "papermill": {
     "duration": 37881.158873,
     "end_time": "2024-10-15T12:36:27.051771",
     "exception": false,
     "start_time": "2024-10-15T02:05:05.892898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 3.8090, Train Accuracy: 0.1128\n",
      "Validation Accuracy: 0.1809\n",
      "New best model saved at epoch 1 with val accuracy: 0.1809\n",
      "Epoch [2/1000], Loss: 3.2143, Train Accuracy: 0.2104\n",
      "Validation Accuracy: 0.2512\n",
      "New best model saved at epoch 2 with val accuracy: 0.2512\n",
      "Epoch [3/1000], Loss: 2.9252, Train Accuracy: 0.2676\n",
      "Validation Accuracy: 0.2913\n",
      "New best model saved at epoch 3 with val accuracy: 0.2913\n",
      "Epoch [4/1000], Loss: 2.7421, Train Accuracy: 0.3028\n",
      "Validation Accuracy: 0.3196\n",
      "New best model saved at epoch 4 with val accuracy: 0.3196\n",
      "Epoch [5/1000], Loss: 2.6099, Train Accuracy: 0.3310\n",
      "Validation Accuracy: 0.3413\n",
      "New best model saved at epoch 5 with val accuracy: 0.3413\n",
      "Epoch [6/1000], Loss: 2.5080, Train Accuracy: 0.3527\n",
      "Validation Accuracy: 0.3567\n",
      "New best model saved at epoch 6 with val accuracy: 0.3567\n",
      "Epoch [7/1000], Loss: 2.4181, Train Accuracy: 0.3718\n",
      "Validation Accuracy: 0.3737\n",
      "New best model saved at epoch 7 with val accuracy: 0.3737\n",
      "Epoch [8/1000], Loss: 2.3477, Train Accuracy: 0.3865\n",
      "Validation Accuracy: 0.3877\n",
      "New best model saved at epoch 8 with val accuracy: 0.3877\n",
      "Epoch [9/1000], Loss: 2.2924, Train Accuracy: 0.3972\n",
      "Validation Accuracy: 0.4082\n",
      "New best model saved at epoch 9 with val accuracy: 0.4082\n",
      "Epoch [10/1000], Loss: 2.2399, Train Accuracy: 0.4120\n",
      "Validation Accuracy: 0.4029\n",
      "Epoch [11/1000], Loss: 2.1998, Train Accuracy: 0.4218\n",
      "Validation Accuracy: 0.4140\n",
      "New best model saved at epoch 11 with val accuracy: 0.4140\n",
      "Epoch [12/1000], Loss: 2.1635, Train Accuracy: 0.4291\n",
      "Validation Accuracy: 0.4197\n",
      "New best model saved at epoch 12 with val accuracy: 0.4197\n",
      "Epoch [13/1000], Loss: 2.1276, Train Accuracy: 0.4343\n",
      "Validation Accuracy: 0.4212\n",
      "New best model saved at epoch 13 with val accuracy: 0.4212\n",
      "Epoch [14/1000], Loss: 2.0900, Train Accuracy: 0.4451\n",
      "Validation Accuracy: 0.4292\n",
      "New best model saved at epoch 14 with val accuracy: 0.4292\n",
      "Epoch [15/1000], Loss: 2.0657, Train Accuracy: 0.4529\n",
      "Validation Accuracy: 0.4403\n",
      "New best model saved at epoch 15 with val accuracy: 0.4403\n",
      "Epoch [16/1000], Loss: 2.0352, Train Accuracy: 0.4582\n",
      "Validation Accuracy: 0.4434\n",
      "New best model saved at epoch 16 with val accuracy: 0.4434\n",
      "Epoch [17/1000], Loss: 2.0114, Train Accuracy: 0.4601\n",
      "Validation Accuracy: 0.4529\n",
      "New best model saved at epoch 17 with val accuracy: 0.4529\n",
      "Epoch [18/1000], Loss: 1.9881, Train Accuracy: 0.4665\n",
      "Validation Accuracy: 0.4514\n",
      "Epoch [19/1000], Loss: 1.9646, Train Accuracy: 0.4708\n",
      "Validation Accuracy: 0.4532\n",
      "New best model saved at epoch 19 with val accuracy: 0.4532\n",
      "Epoch [20/1000], Loss: 1.9457, Train Accuracy: 0.4777\n",
      "Validation Accuracy: 0.4512\n",
      "Epoch [21/1000], Loss: 1.9137, Train Accuracy: 0.4871\n",
      "Validation Accuracy: 0.4529\n",
      "Epoch [22/1000], Loss: 1.9057, Train Accuracy: 0.4864\n",
      "Validation Accuracy: 0.4650\n",
      "New best model saved at epoch 22 with val accuracy: 0.4650\n",
      "Epoch [23/1000], Loss: 1.8877, Train Accuracy: 0.4904\n",
      "Validation Accuracy: 0.4572\n",
      "Epoch [24/1000], Loss: 1.8672, Train Accuracy: 0.4965\n",
      "Validation Accuracy: 0.4673\n",
      "New best model saved at epoch 24 with val accuracy: 0.4673\n",
      "Epoch [25/1000], Loss: 1.8539, Train Accuracy: 0.4961\n",
      "Validation Accuracy: 0.4677\n",
      "New best model saved at epoch 25 with val accuracy: 0.4677\n",
      "Epoch [26/1000], Loss: 1.8425, Train Accuracy: 0.5029\n",
      "Validation Accuracy: 0.4711\n",
      "New best model saved at epoch 26 with val accuracy: 0.4711\n",
      "Epoch [27/1000], Loss: 1.8276, Train Accuracy: 0.5056\n",
      "Validation Accuracy: 0.4693\n",
      "Epoch [28/1000], Loss: 1.8133, Train Accuracy: 0.5057\n",
      "Validation Accuracy: 0.4744\n",
      "New best model saved at epoch 28 with val accuracy: 0.4744\n",
      "Epoch [29/1000], Loss: 1.7902, Train Accuracy: 0.5133\n",
      "Validation Accuracy: 0.4725\n",
      "Epoch [30/1000], Loss: 1.7825, Train Accuracy: 0.5149\n",
      "Validation Accuracy: 0.4737\n",
      "Epoch [31/1000], Loss: 1.7687, Train Accuracy: 0.5173\n",
      "Validation Accuracy: 0.4882\n",
      "New best model saved at epoch 31 with val accuracy: 0.4882\n",
      "Epoch [32/1000], Loss: 1.7642, Train Accuracy: 0.5178\n",
      "Validation Accuracy: 0.4858\n",
      "Epoch [33/1000], Loss: 1.7448, Train Accuracy: 0.5242\n",
      "Validation Accuracy: 0.4861\n",
      "Epoch [34/1000], Loss: 1.7335, Train Accuracy: 0.5265\n",
      "Validation Accuracy: 0.4942\n",
      "New best model saved at epoch 34 with val accuracy: 0.4942\n",
      "Epoch [35/1000], Loss: 1.7244, Train Accuracy: 0.5276\n",
      "Validation Accuracy: 0.4863\n",
      "Epoch [36/1000], Loss: 1.7199, Train Accuracy: 0.5299\n",
      "Validation Accuracy: 0.4903\n",
      "Epoch [37/1000], Loss: 1.7025, Train Accuracy: 0.5349\n",
      "Validation Accuracy: 0.4918\n",
      "Epoch [38/1000], Loss: 1.6931, Train Accuracy: 0.5368\n",
      "Validation Accuracy: 0.5002\n",
      "New best model saved at epoch 38 with val accuracy: 0.5002\n",
      "Epoch [39/1000], Loss: 1.6898, Train Accuracy: 0.5365\n",
      "Validation Accuracy: 0.4990\n",
      "Epoch [40/1000], Loss: 1.6811, Train Accuracy: 0.5380\n",
      "Validation Accuracy: 0.5008\n",
      "New best model saved at epoch 40 with val accuracy: 0.5008\n",
      "Epoch [41/1000], Loss: 1.6654, Train Accuracy: 0.5434\n",
      "Validation Accuracy: 0.4970\n",
      "Epoch [42/1000], Loss: 1.6628, Train Accuracy: 0.5450\n",
      "Validation Accuracy: 0.4946\n",
      "Epoch [43/1000], Loss: 1.6566, Train Accuracy: 0.5428\n",
      "Validation Accuracy: 0.4963\n",
      "Epoch [44/1000], Loss: 1.6382, Train Accuracy: 0.5488\n",
      "Validation Accuracy: 0.4964\n",
      "Epoch [45/1000], Loss: 1.6394, Train Accuracy: 0.5474\n",
      "Validation Accuracy: 0.5014\n",
      "New best model saved at epoch 45 with val accuracy: 0.5014\n",
      "Epoch [46/1000], Loss: 1.6208, Train Accuracy: 0.5551\n",
      "Validation Accuracy: 0.4970\n",
      "Epoch [47/1000], Loss: 1.6212, Train Accuracy: 0.5529\n",
      "Validation Accuracy: 0.5055\n",
      "New best model saved at epoch 47 with val accuracy: 0.5055\n",
      "Epoch [48/1000], Loss: 1.6126, Train Accuracy: 0.5538\n",
      "Validation Accuracy: 0.5027\n",
      "Epoch [49/1000], Loss: 1.6033, Train Accuracy: 0.5572\n",
      "Validation Accuracy: 0.4989\n",
      "Epoch [50/1000], Loss: 1.6043, Train Accuracy: 0.5593\n",
      "Validation Accuracy: 0.5019\n",
      "Epoch [51/1000], Loss: 1.5886, Train Accuracy: 0.5616\n",
      "Validation Accuracy: 0.4979\n",
      "Epoch [52/1000], Loss: 1.5884, Train Accuracy: 0.5599\n",
      "Validation Accuracy: 0.5055\n",
      "Epoch [53/1000], Loss: 1.5794, Train Accuracy: 0.5624\n",
      "Validation Accuracy: 0.5040\n",
      "Epoch [54/1000], Loss: 1.4869, Train Accuracy: 0.5857\n",
      "Validation Accuracy: 0.5218\n",
      "New best model saved at epoch 54 with val accuracy: 0.5218\n",
      "Epoch [55/1000], Loss: 1.4713, Train Accuracy: 0.5895\n",
      "Validation Accuracy: 0.5234\n",
      "New best model saved at epoch 55 with val accuracy: 0.5234\n",
      "Epoch [56/1000], Loss: 1.4566, Train Accuracy: 0.5939\n",
      "Validation Accuracy: 0.5258\n",
      "New best model saved at epoch 56 with val accuracy: 0.5258\n",
      "Epoch [57/1000], Loss: 1.4518, Train Accuracy: 0.5947\n",
      "Validation Accuracy: 0.5243\n",
      "Epoch [58/1000], Loss: 1.4461, Train Accuracy: 0.5950\n",
      "Validation Accuracy: 0.5238\n",
      "Epoch [59/1000], Loss: 1.4419, Train Accuracy: 0.5953\n",
      "Validation Accuracy: 0.5227\n",
      "Epoch [60/1000], Loss: 1.4370, Train Accuracy: 0.5975\n",
      "Validation Accuracy: 0.5283\n",
      "New best model saved at epoch 60 with val accuracy: 0.5283\n",
      "Epoch [61/1000], Loss: 1.4383, Train Accuracy: 0.5978\n",
      "Validation Accuracy: 0.5365\n",
      "New best model saved at epoch 61 with val accuracy: 0.5365\n",
      "Epoch [62/1000], Loss: 1.4364, Train Accuracy: 0.5937\n",
      "Validation Accuracy: 0.5286\n",
      "Epoch [63/1000], Loss: 1.4303, Train Accuracy: 0.5989\n",
      "Validation Accuracy: 0.5320\n",
      "Epoch [64/1000], Loss: 1.4267, Train Accuracy: 0.5998\n",
      "Validation Accuracy: 0.5239\n",
      "Epoch [65/1000], Loss: 1.4192, Train Accuracy: 0.6014\n",
      "Validation Accuracy: 0.5289\n",
      "Epoch [66/1000], Loss: 1.4090, Train Accuracy: 0.6043\n",
      "Validation Accuracy: 0.5300\n",
      "Epoch [67/1000], Loss: 1.4128, Train Accuracy: 0.5998\n",
      "Validation Accuracy: 0.5319\n",
      "Epoch [68/1000], Loss: 1.3679, Train Accuracy: 0.6162\n",
      "Validation Accuracy: 0.5389\n",
      "New best model saved at epoch 68 with val accuracy: 0.5389\n",
      "Epoch [69/1000], Loss: 1.3603, Train Accuracy: 0.6183\n",
      "Validation Accuracy: 0.5416\n",
      "New best model saved at epoch 69 with val accuracy: 0.5416\n",
      "Epoch [70/1000], Loss: 1.3551, Train Accuracy: 0.6207\n",
      "Validation Accuracy: 0.5392\n",
      "Epoch [71/1000], Loss: 1.3501, Train Accuracy: 0.6189\n",
      "Validation Accuracy: 0.5398\n",
      "Epoch [72/1000], Loss: 1.3449, Train Accuracy: 0.6221\n",
      "Validation Accuracy: 0.5404\n",
      "Epoch [73/1000], Loss: 1.3460, Train Accuracy: 0.6207\n",
      "Validation Accuracy: 0.5344\n",
      "Epoch [74/1000], Loss: 1.3370, Train Accuracy: 0.6210\n",
      "Validation Accuracy: 0.5428\n",
      "New best model saved at epoch 74 with val accuracy: 0.5428\n",
      "Epoch [75/1000], Loss: 1.3397, Train Accuracy: 0.6220\n",
      "Validation Accuracy: 0.5382\n",
      "Epoch [76/1000], Loss: 1.3325, Train Accuracy: 0.6250\n",
      "Validation Accuracy: 0.5387\n",
      "Epoch [77/1000], Loss: 1.3262, Train Accuracy: 0.6227\n",
      "Validation Accuracy: 0.5386\n",
      "Epoch [78/1000], Loss: 1.3319, Train Accuracy: 0.6253\n",
      "Validation Accuracy: 0.5389\n",
      "Epoch [79/1000], Loss: 1.3346, Train Accuracy: 0.6221\n",
      "Validation Accuracy: 0.5358\n",
      "Epoch [80/1000], Loss: 1.3267, Train Accuracy: 0.6260\n",
      "Validation Accuracy: 0.5386\n",
      "Epoch [81/1000], Loss: 1.3027, Train Accuracy: 0.6307\n",
      "Validation Accuracy: 0.5409\n",
      "Epoch [82/1000], Loss: 1.2989, Train Accuracy: 0.6330\n",
      "Validation Accuracy: 0.5430\n",
      "New best model saved at epoch 82 with val accuracy: 0.5430\n",
      "Epoch [83/1000], Loss: 1.2993, Train Accuracy: 0.6303\n",
      "Validation Accuracy: 0.5437\n",
      "New best model saved at epoch 83 with val accuracy: 0.5437\n",
      "Epoch [84/1000], Loss: 1.2854, Train Accuracy: 0.6355\n",
      "Validation Accuracy: 0.5426\n",
      "Epoch [85/1000], Loss: 1.2986, Train Accuracy: 0.6310\n",
      "Validation Accuracy: 0.5414\n",
      "Epoch [86/1000], Loss: 1.2816, Train Accuracy: 0.6357\n",
      "Validation Accuracy: 0.5394\n",
      "Epoch [87/1000], Loss: 1.2884, Train Accuracy: 0.6356\n",
      "Validation Accuracy: 0.5475\n",
      "New best model saved at epoch 87 with val accuracy: 0.5475\n",
      "Epoch [88/1000], Loss: 1.2821, Train Accuracy: 0.6329\n",
      "Validation Accuracy: 0.5399\n",
      "Epoch [89/1000], Loss: 1.2880, Train Accuracy: 0.6368\n",
      "Validation Accuracy: 0.5500\n",
      "New best model saved at epoch 89 with val accuracy: 0.5500\n",
      "Epoch [90/1000], Loss: 1.2862, Train Accuracy: 0.6344\n",
      "Validation Accuracy: 0.5457\n",
      "Epoch [91/1000], Loss: 1.2907, Train Accuracy: 0.6327\n",
      "Validation Accuracy: 0.5456\n",
      "Epoch [92/1000], Loss: 1.2882, Train Accuracy: 0.6359\n",
      "Validation Accuracy: 0.5440\n",
      "Epoch [93/1000], Loss: 1.2793, Train Accuracy: 0.6396\n",
      "Validation Accuracy: 0.5445\n",
      "Epoch [94/1000], Loss: 1.2764, Train Accuracy: 0.6366\n",
      "Validation Accuracy: 0.5405\n",
      "Epoch [95/1000], Loss: 1.2758, Train Accuracy: 0.6381\n",
      "Validation Accuracy: 0.5422\n",
      "Epoch [96/1000], Loss: 1.2745, Train Accuracy: 0.6372\n",
      "Validation Accuracy: 0.5505\n",
      "New best model saved at epoch 96 with val accuracy: 0.5505\n",
      "Epoch [97/1000], Loss: 1.2598, Train Accuracy: 0.6413\n",
      "Validation Accuracy: 0.5445\n",
      "Epoch [98/1000], Loss: 1.2594, Train Accuracy: 0.6426\n",
      "Validation Accuracy: 0.5424\n",
      "Epoch [99/1000], Loss: 1.2595, Train Accuracy: 0.6420\n",
      "Validation Accuracy: 0.5436\n",
      "Epoch [100/1000], Loss: 1.2532, Train Accuracy: 0.6438\n",
      "Validation Accuracy: 0.5412\n",
      "Epoch [101/1000], Loss: 1.2618, Train Accuracy: 0.6394\n",
      "Validation Accuracy: 0.5497\n",
      "Epoch [102/1000], Loss: 1.2634, Train Accuracy: 0.6373\n",
      "Validation Accuracy: 0.5443\n",
      "Epoch [103/1000], Loss: 1.2502, Train Accuracy: 0.6432\n",
      "Validation Accuracy: 0.5456\n",
      "Epoch [104/1000], Loss: 1.2500, Train Accuracy: 0.6451\n",
      "Validation Accuracy: 0.5460\n",
      "Epoch [105/1000], Loss: 1.2569, Train Accuracy: 0.6421\n",
      "Validation Accuracy: 0.5441\n",
      "Epoch [106/1000], Loss: 1.2467, Train Accuracy: 0.6440\n",
      "Validation Accuracy: 0.5422\n",
      "Early stopping at epoch 106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - 모델 학습 및 검증을 수행하는 메인 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # 학습 루프\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features, batch_labels = batch_features.cuda(), batch_labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    # 학습 결과 출력\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct / len(train_dataset)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # 검증 루프\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for val_features, val_labels in val_loader:\n",
    "            val_features, val_labels = val_features.cuda(), val_labels.cuda()\n",
    "            val_outputs = model(val_features)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    # 검증 정확도 출력\n",
    "    val_accuracy = val_correct / len(val_dataset)\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 스케줄러를 통해 학습률 조정\n",
    "    scheduler.step(val_accuracy)\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        early_stopping_counter = 0\n",
    "        # 모델 저장\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"New best model saved at epoch {epoch + 1} with val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6bebb",
   "metadata": {
    "papermill": {
     "duration": 0.023781,
     "end_time": "2024-10-15T12:36:27.099491",
     "exception": false,
     "start_time": "2024-10-15T12:36:27.075710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 12: 테스트 데이터 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc4f719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T12:36:27.149187Z",
     "iopub.status.busy": "2024-10-15T12:36:27.148807Z",
     "iopub.status.idle": "2024-10-15T12:37:35.223255Z",
     "shell.execute_reply": "2024-10-15T12:37:35.222351Z"
    },
    "papermill": {
     "duration": 68.128813,
     "end_time": "2024-10-15T12:37:35.252131",
     "exception": false,
     "start_time": "2024-10-15T12:36:27.123318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/145435278.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))  # 가장 성능이 좋은 모델 로드\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file has been saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - 가장 성능이 좋은 모델을 로드하고 테스트 데이터에 대한 예측을 수행\n",
    "model.load_state_dict(torch.load('best_model.pth'))  # 가장 성능이 좋은 모델 로드\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test = np.load('/kaggle/input/2024-ai-challenge/testset.npy')  # 테스트 데이터 불러오기\n",
    "    test_dataset = CustomDataset(test, np.zeros((test.shape[0], 100)), transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    for test_features, _ in test_loader:\n",
    "        test_features = test_features.cuda()\n",
    "        outputs = model(test_features)\n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "# 예측 결과 합치기\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# 예측된 클래스의 인덱스를 얻음\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "submission_df = pd.DataFrame({\n",
    "    'id_idx': np.arange(len(predicted_classes)),\n",
    "    'label': predicted_classes\n",
    "})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "submission_filename = 'submission.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"Submission file has been saved as '{submission_filename}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9473141,
     "sourceId": 84531,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37977.468265,
   "end_time": "2024-10-15T12:37:36.999991",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-15T02:04:39.531726",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
